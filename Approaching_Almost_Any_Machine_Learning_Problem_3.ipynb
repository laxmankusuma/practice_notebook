{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arabic-olympus",
   "metadata": {},
   "source": [
    "# by Abhishek Thakur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-dover",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-closure",
   "metadata": {},
   "source": [
    "If we talk about classification problems, the most common metrics used are:\n",
    "<br>\n",
    "- Accuracy\n",
    "<br>\n",
    "- Precision (P)\n",
    "<br>\n",
    "- Recall (R)\n",
    "<br>\n",
    "- F1 score (F1)\n",
    "<br>\n",
    "- Area under the ROC (Receiver Operating Characteristic) curve or simply AUC (AUC)\n",
    "<br>\n",
    "- Log loss\n",
    "<br>\n",
    "- Precision at k (P@k)\n",
    "<br>\n",
    "- Average precision at k (AP@k)\n",
    "<br>\n",
    "- Mean average precision at k (MAP@k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-penetration",
   "metadata": {},
   "source": [
    "When it comes to regression, the most commonly used evaluation metrics are:\n",
    "<br>\n",
    "- Mean absolute error (MAE)\n",
    "<br>\n",
    "- Mean squared error (MSE)\n",
    "<br>\n",
    "- Root mean squared error (RMSE)\n",
    "<br>\n",
    "- Root mean squared logarithmic error (RMSLE)\n",
    "<br>\n",
    "- Mean percentage error (MPE)\n",
    "<br>\n",
    "- Mean absolute percentage error (MAPE)\n",
    "<br>\n",
    "- R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-final",
   "metadata": {},
   "source": [
    "The first step is to divide the data described above into two equal sets of 100 images\n",
    "each, i.e. training and validation set. In both the sets, we have 50 positive and 50\n",
    "negative samples.\n",
    "<br>\n",
    "When we have an equal number of positive and negative samples in a binary\n",
    "classification metric, we generally use accuracy, precision, recall and f1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-california",
   "metadata": {},
   "source": [
    "**Accuracy:** It is one of the most straightforward metrics used in machine learning.\n",
    "It defines how accurate your model is. For the problem described above, if you\n",
    "build a model that classifies 90 images accurately, your accuracy is 90% or 0.90. If\n",
    "only 83 images are classified correctly, the accuracy of your model is 83% or 0.83.\n",
    "Simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-desire",
   "metadata": {},
   "source": [
    "Python code for calculating accuracy is also quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "multiple-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    '''\n",
    "    Function to calculate accuracy \n",
    "    :param y_true: list of true values \n",
    "    :param y_pred: list of predicted values \n",
    "    :return: accuracy score\n",
    "    '''\n",
    "    \n",
    "    # initialize a simple counter for correct predictions\n",
    "    correct_counter = 0\n",
    "    \n",
    "    # loop over all elements of y_true\n",
    "    # and y_pred \"together\"\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            # if prediction is equal to truth, increase the counter\n",
    "            correct_counter += 1\n",
    "    \n",
    "    # return accuracy\n",
    "    # which is correct predictions over the number of samples\n",
    "    return correct_counter / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-breed",
   "metadata": {},
   "source": [
    "We can also calculate accuracy using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fitted-pennsylvania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "metrics.accuracy_score(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acoustic-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(l1, l2) # its is our method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-newsletter",
   "metadata": {},
   "source": [
    "Now, let’s say we change the dataset a bit such that there are 180 chest x-ray images\n",
    "which do not have pneumothorax and only 20 with pneumothorax. Even in this\n",
    "case, we will create the training and validation sets with the same ratio of positive\n",
    "to negative (pneumothorax to non- pneumothorax) targets. In each set, we have 90\n",
    "non- pneumothorax and 10 pneumothorax images. If you say that all images in the\n",
    "validation set are non-pneumothorax, what would your accuracy be? Let’s see; you\n",
    "classified 90% of the images correctly. So, your accuracy is 90%.\n",
    "<br>\n",
    "But look at it one more time.\n",
    "<br>\n",
    "You didn’t even build a model and got an accuracy of 90%. That seems kind of\n",
    "useless. If we look carefully, we will see that the dataset is skewed, i.e., the number\n",
    "of samples in one class outnumber the number of samples in other class by a lot. In\n",
    "these kinds of cases, it is not advisable to use accuracy as an evaluation metric as it\n",
    "is not representative of the data. So, you might get high accuracy, but your model\n",
    "will probably not perform that well when it comes to real-world samples, and you\n",
    "won’t be able to explain to your managers why.\n",
    "<br>\n",
    "In these cases, it’s better to look at other metrics such as **precision.**\n",
    "<br>\n",
    "Before learning about precision, we need to know a few terms. Here we have\n",
    "assumed that chest x-ray images with pneumothorax are positive class (1) and\n",
    "without pneumothorax are negative class (0).\n",
    "<br>\n",
    "**True positive (TP):** Given an image, if your model predicts the image has\n",
    "pneumothorax, and the actual target for that image has pneumothorax, it is\n",
    "considered a true positive.\n",
    "<br>\n",
    "**True negative (TN):** Given an image, if your model predicts that the image does not\n",
    "have pneumothorax and the actual target says that it is a non-pneumothorax image,\n",
    "it is considered a true negative.\n",
    "<br>\n",
    "In simple words, if your model correctly predicts positive class, it is true positive,\n",
    "and if your model accurately predicts negative class, it is a true negative.\n",
    "<br>\n",
    "**False positive (FP):** Given an image, if your model predicts pneumothorax and the\n",
    "actual target for that image is non- pneumothorax, it a false positive.\n",
    "<br>\n",
    "**False negative (FN):** Given an image, if your model predicts non-pneumothorax\n",
    "and the actual target for that image is pneumothorax, it is a false negative.\n",
    "<br>\n",
    "In simple words, if your model incorrectly (or falsely) predicts positive class, it is\n",
    "a false positive. If your model incorrectly (or falsely) predicts negative class, it is a\n",
    "false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incomplete-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Positives \n",
    "    :param y_true: list of true values \n",
    "    :param y_pred: list of predicted values \n",
    "    :return: number of true positives \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize\n",
    "    tp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    "    return tp\n",
    "\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Negatives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of true negatives\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    tn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn += 1\n",
    "    return tn\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Positives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of false positives\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    fp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "    return fp\n",
    "\n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Negatives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of false negatives\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    fn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-wiring",
   "metadata": {},
   "source": [
    "The way I have implemented these here is quite simple and works only for binary\n",
    "classification. Let’s check these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "revised-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comprehensive-contrary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "buried-membership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "corrected-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "separated-printer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_negative(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-solid",
   "metadata": {},
   "source": [
    "If we have to define accuracy using the terms described above, we can write:\n",
    "<br>\n",
    "**Accuracy Score** = (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-police",
   "metadata": {},
   "source": [
    "We can now quickly implement accuracy score using TP, TN, FP and FN in python.\n",
    "Let’s call it accuracy_v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "restricted-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_v2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy using tp/tn/fp/fn\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: accuracy score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    accuracy_score = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-nursing",
   "metadata": {},
   "source": [
    "We can quickly check the correctness of this function by comparing it to our\n",
    "previous implementation and scikit-learn version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unavailable-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spare-mountain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "several-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_v2(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "historic-metabolism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-newcastle",
   "metadata": {},
   "source": [
    "**Precision** = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sought-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate precision\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: precision score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "identical-castle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "precision(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-movie",
   "metadata": {},
   "source": [
    "**Recall** = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ambient-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Function to calculate recall\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: recall score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "diverse-hindu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "recall(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-gregory",
   "metadata": {},
   "source": [
    "**For a “good” model, our precision and recall values should be high.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-methodology",
   "metadata": {},
   "source": [
    "**F1 score is a metric that combines both precision and recall.**\n",
    "<br>\n",
    "It is defined as a simple\n",
    "weighted average (harmonic mean) of precision and recall.\n",
    "<br>\n",
    "**F1 = 2PR / (P + R)**\n",
    "<br>\n",
    "i.e **F1 = 2TP / (2TP + FP + FN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "catholic-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate f1 score\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: f1 score\n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    score = 2 * p * r / (p + r)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "muslim-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0,1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "y_pred = [0, 0, 1, 0, 0, 0, 1, 0, 0, 0,1, 0, 0, 0, 0, 0, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "collectible-copying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "painful-consumption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-instrument",
   "metadata": {},
   "source": [
    "Instead of looking at precision and recall individually, you can also just look at F1\n",
    "score. Same as for precision, recall and accuracy, F1 score also ranges from 0 to 1,\n",
    "and a perfect prediction model has an F1 of 1. When dealing with datasets that have\n",
    "skewed targets, we should look at F1 (or precision and recall) instead of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-panel",
   "metadata": {},
   "source": [
    "The first one is **TPR or True Positive Rate or sensitivity.**, which is the same as recall.\n",
    "**TPR = TP / (TP + FN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "swedish-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate tpr\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: tpr/recall\n",
    "    \"\"\"\n",
    "    return recall(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-counter",
   "metadata": {},
   "source": [
    "**FPR or False Positive Rate**, which is defined as:\n",
    "**FPR = FP / (TN + FP)**\n",
    "<br>\n",
    "**1 - FPR** is known as **specificity or True Negative Rate or TNR.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-scout",
   "metadata": {},
   "source": [
    "Area Under ROC Curve or **Area Under Curve** or\n",
    "just simply **AUC**. There are many ways to calculate the area under the ROC curve.\n",
    "For this particular purpose, we will stick to the fantastic implementation by scikitlearn.\n",
    "<br>\n",
    "**Receiver Operating Characteristic (ROC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "unable-petroleum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8300000000000001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1,0, 0, 1, 0, 1, 0, 0, 1]\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,0.9, 0.5, 0.3, 0.66, 0.3, 0.2,0.85, 0.15, 0.99]\n",
    "\n",
    "metrics.roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-tours",
   "metadata": {},
   "source": [
    "AUC values range from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-catch",
   "metadata": {},
   "source": [
    "- **AUC = 1** implies you have a perfect model.\n",
    "<br>\n",
    "- **AUC = 0** implies that your model is very bad (or very good!).\n",
    "<br>\n",
    "- **AUC = 0.5** implies that your predictions are random. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-republican",
   "metadata": {},
   "source": [
    "**AUC is a widely used metric for skewed binary classification tasks in the industry**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-reservation",
   "metadata": {},
   "source": [
    "In case\n",
    "of a binary classification problem, we define log loss as:\n",
    "<br>\n",
    "**Log Loss = - 1.0 * ( target * log(prediction) + (1 - target) * log(1 - prediction) )**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-magnet",
   "metadata": {},
   "source": [
    "**we use weighted f1 metric for multi-class problems**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-botswana",
   "metadata": {},
   "source": [
    "In binary or multi-class classification, it is also quite popular to take a look at\n",
    "**confusion matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-sellers",
   "metadata": {},
   "source": [
    "**Confusion matrix** gives an easy way to calculate different metrics that we have\n",
    "discussed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "weekly-marketplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 48.5, 'Predicted Labels')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "# some targets\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "\n",
    "#some predictions\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "# get confusion matrix from sklearn\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# plot using matplotlib and seaborn\n",
    "plt.figure(figsize=(10,10))\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0,\n",
    "                            as_cmap=True)\n",
    "sns.set(font_scale=2.5)\n",
    "sns.heatmap(cm, annot=True, cmap=cmap, cbar=False)\n",
    "\n",
    "plt.ylabel('Actual Labels', fontsize=20)\n",
    "plt.xlabel('Predicted Labels', fontsize=20)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-consent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "precious-potter",
   "metadata": {},
   "source": [
    "metrics for **multi-label classification problems** are\n",
    "<br>\n",
    "- Precision at k (P@k)\n",
    "<br>\n",
    "- Average precision at k (AP@k)\n",
    "<br>\n",
    "- Mean average precision at k (MAP@k)\n",
    "<br>\n",
    "- Log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "descending-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    This function calculates precision at k\n",
    "    for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :param k: the value for k\n",
    "    :return: precision at a given value k\n",
    "    \"\"\"\n",
    "    \n",
    "    # if k is 0, return 0. we should never have this\n",
    "    # as k is always >= 1\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    # we are interested only in top-k predictions\n",
    "    y_pred = y_pred[:k]\n",
    "    \n",
    "    # convert predictions to set\n",
    "    pred_set = set(y_pred)\n",
    "    \n",
    "    # convert actual values to set\n",
    "    true_set = set(y_true)\n",
    "    \n",
    "    # find common values\n",
    "    common_values = pred_set.intersection(true_set)\n",
    "    \n",
    "    # return length of common values over k\n",
    "    return len(common_values) / len(y_pred[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-recognition",
   "metadata": {},
   "source": [
    "Now, we have **average precision at k or AP@k**. AP@k is calculated using P@k.\n",
    "For example, if we have to calculate AP@3, we calculate P@1, P@2 and P@3 and\n",
    "then divide the sum by 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "textile-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    This function calculates average precision at k\n",
    "    for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\\\n",
    "    :return: average precision at a given value k\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize p@k list of values\n",
    "    pk_values = []\n",
    "    \n",
    "    # loop over all k. from 1 to k+1\n",
    "    for i in range(1, k + 1):\n",
    "        # calculate p@i and append to list\n",
    "        pk_values.append(pk(y_true, y_pred, i))\n",
    "        \n",
    "    # if we have no values in the list, return 0\n",
    "    if len(pk_values) == 0:\n",
    "        return 0\n",
    "    # else, we return the sum of list over length of list\n",
    "    return sum(pk_values) / len(pk_values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "usual-zoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            y_true=[1, 2, 3],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@1=0.0\n",
      "            \n",
      "\n",
      "            y_true=[1, 2, 3],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@2=0.25\n",
      "            \n",
      "\n",
      "            y_true=[1, 2, 3],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@3=0.38888888888888884\n",
      "            \n",
      "\n",
      "            y_true=[0, 2],\n",
      "            y_pred=[1],\n",
      "            AP@1=0.0\n",
      "            \n",
      "\n",
      "            y_true=[0, 2],\n",
      "            y_pred=[1],\n",
      "            AP@2=0.0\n",
      "            \n",
      "\n",
      "            y_true=[0, 2],\n",
      "            y_pred=[1],\n",
      "            AP@3=0.0\n",
      "            \n",
      "\n",
      "            y_true=[1],\n",
      "            y_pred=[0, 2, 3],\n",
      "            AP@1=0.0\n",
      "            \n",
      "\n",
      "            y_true=[1],\n",
      "            y_pred=[0, 2, 3],\n",
      "            AP@2=0.0\n",
      "            \n",
      "\n",
      "            y_true=[1],\n",
      "            y_pred=[0, 2, 3],\n",
      "            AP@3=0.0\n",
      "            \n",
      "\n",
      "            y_true=[2, 3],\n",
      "            y_pred=[2, 3, 4, 0],\n",
      "            AP@1=1.0\n",
      "            \n",
      "\n",
      "            y_true=[2, 3],\n",
      "            y_pred=[2, 3, 4, 0],\n",
      "            AP@2=1.0\n",
      "            \n",
      "\n",
      "            y_true=[2, 3],\n",
      "            y_pred=[2, 3, 4, 0],\n",
      "            AP@3=0.8888888888888888\n",
      "            \n",
      "\n",
      "            y_true=[1, 0],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@1=1.0\n",
      "            \n",
      "\n",
      "            y_true=[1, 0],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@2=1.0\n",
      "            \n",
      "\n",
      "            y_true=[1, 0],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@3=0.8888888888888888\n",
      "            \n",
      "\n",
      "            y_true=[],\n",
      "            y_pred=[0],\n",
      "            AP@1=0.0\n",
      "            \n",
      "\n",
      "            y_true=[],\n",
      "            y_pred=[0],\n",
      "            AP@2=0.0\n",
      "            \n",
      "\n",
      "            y_true=[],\n",
      "            y_pred=[0],\n",
      "            AP@3=0.0\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "y_true = [\n",
    "    [1, 2, 3],\n",
    "    [0, 2],\n",
    "    [1],\n",
    "    [2, 3],\n",
    "    [1, 0],\n",
    "    []\n",
    "]\n",
    "y_pred = [\n",
    "    [0, 1, 2],\n",
    "    [1],\n",
    "    [0, 2, 3],\n",
    "    [2, 3, 4, 0],\n",
    "    [0, 1, 2],\n",
    "    [0]\n",
    "]\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    for j in range(1, 4):\n",
    "        print(\n",
    "            f'''\n",
    "            y_true={y_true[i]},\n",
    "            y_pred={y_pred[i]},\n",
    "            AP@{j}={apk(y_true[i], y_pred[i], k=j)}\n",
    "            '''\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-folder",
   "metadata": {},
   "source": [
    "In machine learning,\n",
    "we are interested in all samples, and that’s why we have **mean average precision\n",
    "at k or MAP@k. MAP@k** is just an average of AP@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fundamental-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    This function calculates mean avg precision at k\n",
    "    for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :return: mean avg precision at a given value k\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize empty list for apk values    \n",
    "    apk_values = []\n",
    "    \n",
    "    # loop over all samples\n",
    "    for i in range(len(y_true)):\n",
    "        # store apk values for every sample\n",
    "        apk_values.append(\n",
    "            apk(y_true[i], y_pred[i], k=k)\n",
    "        )\n",
    "    \n",
    "    # return mean of apk values list\n",
    "    return sum(apk_values) / len(apk_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "breathing-fiber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(y_true, y_pred, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "prospective-memorial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "powerful-officer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3611111111111111"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "equipped-telephone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34722222222222215"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(y_true, y_pred, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-vacuum",
   "metadata": {},
   "source": [
    "P@k, AP@k and MAP@k all range from 0 to 1 with 1 being the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-saudi",
   "metadata": {},
   "source": [
    "**The most common metric in regression** is error. **Error** is simple and very easy to\n",
    "understand.\n",
    "<br>\n",
    "**Error = True Value – Predicted Value**\n",
    "<br>\n",
    "**Absolute error** is just absolute of the above.\n",
    "Absolute Error = Abs ( True Value – Predicted Value )\n",
    "<br>\n",
    "Then we have **mean absolute error (MAE)**. It’s just mean of all absolute errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "disciplinary-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates mae\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean absolute error\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    \n",
    "    # loop over all samples in the true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate absolute error\n",
    "        # and add to error\n",
    "        error += np.abs(yt - yp)\n",
    "    # return mean error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-corps",
   "metadata": {},
   "source": [
    "Similarly, we have squared error and **mean squared error (MSE).**\n",
    "<br>\n",
    "**Squared Error = ( True Value – Predicted Value )2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "weekly-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates mse\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean squared error\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    \n",
    "    # loop over all samples in the true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate squared error\n",
    "        # and add to error\n",
    "        error += (yt - yp) ** 2    \n",
    "    # return mean error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-dimension",
   "metadata": {},
   "source": [
    "MSE and **RMSE (root mean squared error)** are the most popular metrics used in\n",
    "evaluating regression models.\n",
    "<br>\n",
    "**RMSE = SQRT ( MSE )**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-closure",
   "metadata": {},
   "source": [
    "Another type of error in same class is **squared logarithmic error**. Some people\n",
    "call it **SLE**, and when we take mean of this error across all samples, it is known as\n",
    "**MSLE (mean squared logarithmic error)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "judicial-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_squared_log_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates msle\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean squared logarithmic error    \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop over all samples in true and predicted list\n",
    "    \n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate squared log error\n",
    "        # and add to error\n",
    "        error += (np.log(1 + yt) - np.log(1 + yp)) ** 2\n",
    "    # return mean error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-transsexual",
   "metadata": {},
   "source": [
    "**Root mean squared logarithmic error** is just a square root of this. It is also known\n",
    "as **RMSLE.**\n",
    "<br>\n",
    "Then we have the percentage error:\n",
    "<br>\n",
    "**Percentage Error = ( ( True Value – Predicted Value ) / True Value ) * 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "upper-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates mpe\n",
    "    :param y_true: list of real numbers, true values\\\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean percentage error\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop over all samples in true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate percentage error\n",
    "        # and add to error\n",
    "        error += (yt - yp) / yt\n",
    "    # return mean percentage error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-underground",
   "metadata": {},
   "source": [
    "And an absolute version of the same (and more common version) is known as **mean\n",
    "absolute percentage error or MAPE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "mental-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_abs_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates MAPE\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean absolute percentage error\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop over all samples in true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate percentage error\n",
    "        # and add to error\n",
    "        error += np.abs(yt - yp) / yt\n",
    "    # return mean percentage error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-queens",
   "metadata": {},
   "source": [
    "**The best thing about regression is that there are only a few most popular metrics\n",
    "that can be applied to almost every regression problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-testimony",
   "metadata": {},
   "source": [
    "Let’s talk about another regression metric known as **R2 (R-squared)**, also known\n",
    "as the **coefficient of determination**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-ghana",
   "metadata": {},
   "source": [
    "In simple words, R-squared says how good your model fits the data. R-squared\n",
    "closer to 1.0 says that the model fits the data quite well, whereas closer 0 means\n",
    "that model isn’t that good. R-squared can also be negative when the model just\n",
    "makes absurd(total nonsense) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "hearing-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates r-squared score\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: r2 score\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate the mean value of true values\n",
    "    mean_true_value = np.mean(y_true)\n",
    "    \n",
    "    # initialize numerator with 0\n",
    "    numerator = 0\n",
    "\n",
    "    # initialize denominator with 0\n",
    "    denominator = 0\n",
    "\n",
    "\n",
    "    # loop over all true and predicted values\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # update numerator\n",
    "        numerator += (yt - yp) ** 2\n",
    "        # update denominator\n",
    "        denominator += (yt - mean_true_value) ** 2\n",
    "        \n",
    "    # calculate the ratio\n",
    "    ratio = numerator / denominator\n",
    "    # return 1 - ratio\n",
    "    return 1 - ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-popularity",
   "metadata": {},
   "source": [
    "One of them which is quite widely used is **quadratic weighted kappa,** also known\n",
    "as **QWK**. It is also known as **Cohen’s kappa**. QWK measures the “agreement”\n",
    "between two “ratings”. The ratings can be any real numbers in 0 to N. And\n",
    "predictions are also in the same range. An agreement can be defined as how close\n",
    "these ratings are to each other. So, it’s suitable for a classification problem with N\n",
    "different categories/classes. If the agreement is high, the score is closer towards 1.0.\n",
    "In the case of low agreement, the score is close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "knowing-irrigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "y_pred = [2, 1, 3, 1, 2, 3, 3, 1, 2]\n",
    "\n",
    "metrics.cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "played-harmony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-cream",
   "metadata": {},
   "source": [
    "You can see that even though accuracy is high, QWK is less. A QWK greater than\n",
    "0.85 is considered to be very good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-baking",
   "metadata": {},
   "source": [
    "An important metric is **Matthew’s Correlation Coefficient (MCC)**.\n",
    "<br>\n",
    "MCC ranges\n",
    "from -1 to 1. 1 is perfect prediction, -1 is imperfect prediction, and 0 is random\n",
    "prediction. The formula for MCC is quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "comic-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates Matthew's Correlation Coefficient\n",
    "    for binary classification.\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: mcc score\n",
    "    \"\"\"\n",
    "    \n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    numerator = (tp * tn) - (fp * fn)\n",
    "    denominator = (\n",
    "        (tp + fp) *\n",
    "        (fn + tn) *\n",
    "        (fp + tn) *\n",
    "        (tp + fn)\n",
    "    )\n",
    "    \n",
    "    denominator = denominator ** 0.5\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-vampire",
   "metadata": {},
   "source": [
    "These are the metrics that can help you get started and will apply to almost every\n",
    "machine learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-conservation",
   "metadata": {},
   "source": [
    "One thing to keep in mind is that to evaluate un-supervised methods, for example,\n",
    "some kind of clustering, it’s better to create or manually label the test set and keep\n",
    "it separate from everything that is going on in your modelling part. When you are\n",
    "done with clustering, you can evaluate the performance on the test set simply by\n",
    "using any of the supervised learning metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-portugal",
   "metadata": {},
   "source": [
    "Once we understand what metric to use for a given problem, we can start looking\n",
    "more deeply into our models for improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-actress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
